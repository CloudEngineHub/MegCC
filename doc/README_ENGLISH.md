# MegCC
![logo](doc/picture/cc.png)
## What is MegCC
MegCC is a deep learning model compiler with features:
* <font color=Red size= 4>**Extremely Light Binary Size**</font> ：Compile mobilenetv1 only， the runtime binary size is only <font color=Red size= 4>**81KB**</font> after stripped
* <font color=Red size= 4>**High Performance**</font> ：Every operation is carefully optimized on arm，<font color=Red size= 4>**faster**</font> than MegEngine
* <font color=Red size= 4>**Portable**</font>：Very easy to run on Android，TEE，BareMeta
* <font color=Red size= 4>**Low Memory Usage and Fast Boot**</font>：With global static memory optimize algorithm inside and static binding at compile time

MegCC compiler is developed based on MLIR infrastructure, now almost all the code generated by the compiler is optimized by hand。MegCC support compile with static shape and dynamic shape，to acheve the minimum binary size, it also support generating the necessary cv operators in C.

After compiled a model, MegCC generates the kernels used by the model and user required cv kernels, at the same time, it do static memory plan, model optimization and dump them into the final tinynn model.

MegCC runtime will load the tinynn model, call the generated kernels to finish the model inference. It is only 81KB binary size to inference mobilenetv1(fp32).

MegCC support Arm64/ArmV7/X86/BareMatal backend now, the supported operator detail ref to [operator lists](doc/opr.md).

### MegCC Structure
![megcc_struct](doc/picture/megcc.png)

## Documentation

#### Get MegCC
* Download release compiler suit, visit [barin++ oss web](https://oss.iap.hh-b.brainpp.cn/megengine-built/megcc)
* Compiler from source, please fellow the [compiler doc](compiler/README.md)
* Build the release tar, please fellow the [release doc](doc/how-to-release.md)

#### How to use MegCC

* Read [如何使用](doc/how-to-use-chinese.md) to see how to compile your models and deploy them，also there is a Engilish doc [how to use](doc/how-to-use.md).

* MegCC runtime is easy to run in standard OS, even no OS([example](runtime/example/README.md)).  
 
**Thanks a lot, please enjoy it**
